# ç¬¬ 15 ç« ï¼šé…ç½®ç³»ç»Ÿ

ä¸åŒç”¨æˆ·æœ‰ä¸åŒéœ€æ±‚ï¼š

- ğŸŒ å›½å†…ç”¨æˆ·ï¼šç”¨ Moonshot Kimi
- ğŸŒ å›½é™…ç”¨æˆ·ï¼šç”¨ OpenAI GPT-4
- ğŸ’° æˆæœ¬æ•æ„Ÿï¼šç”¨ä¾¿å®œçš„æ¨¡å‹
- ğŸš€ æ€§èƒ½ä¼˜å…ˆï¼šç”¨æœ€å¼ºçš„æ¨¡å‹

**é…ç½®ç³»ç»Ÿ**è®© Agent çµæ´»é€‚åº”å„ç§ç¯å¢ƒã€‚

## 15.1 ä¸ºä»€ä¹ˆéœ€è¦é…ç½®ç³»ç»Ÿï¼Ÿ

### åœºæ™¯ 1ï¼šå›¢é˜Ÿåä½œ

ä½ çš„å›¢é˜Ÿæœ‰ä¸åŒçš„å·¥ä½œç¯å¢ƒï¼š

```
å¼€å‘ç¯å¢ƒ (dev)
â”œâ”€ ä½¿ç”¨æœ¬åœ° LLM (Ollama)
â”œâ”€ ä½æˆæœ¬æ¨¡å‹
â””â”€ è¯¦ç»†æ—¥å¿—

ç”Ÿäº§ç¯å¢ƒ (prod)
â”œâ”€ ä½¿ç”¨ GPT-4
â”œâ”€ é«˜æ€§èƒ½æ¨¡å‹
â””â”€ ç®€æ´æ—¥å¿—
```

### åœºæ™¯ 2ï¼šå¤šè´¦å·ç®¡ç†

ä½ æœ‰å¤šä¸ª API è´¦å·ï¼Œéœ€è¦åˆ†åˆ«é…ç½®ï¼š

```bash
# ä¸ªäººè´¦å·
OPENAI_API_KEY=sk-personal-xxx

# å…¬å¸è´¦å·
OPENAI_API_KEY=sk-company-xxx

# æµ‹è¯•è´¦å·
OPENAI_API_KEY=sk-test-xxx
```

### åœºæ™¯ 3ï¼šæ•æ„Ÿä¿¡æ¯ä¿æŠ¤

é…ç½®ä¸­åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼Œä¸èƒ½æäº¤åˆ° Gitï¼š

```json
{
  "api_key": "sk-xxx",  // âŒ ä¸èƒ½æäº¤ï¼
  "database_password": "xxx"  // âŒ ä¸èƒ½æäº¤ï¼
}
```

## 15.2 é…ç½®å±‚çº§

kimi-cli ä½¿ç”¨ä¸‰å±‚é…ç½®ï¼Œä¼˜å…ˆçº§ä»ä½åˆ°é«˜ï¼š

```
ç³»ç»Ÿé…ç½® (System)
  â†“ è¢«è¦†ç›–
ç”¨æˆ·é…ç½® (User)
  â†“ è¢«è¦†ç›–
é¡¹ç›®é…ç½® (Project)
  â†“ è¢«è¦†ç›–
ç¯å¢ƒå˜é‡ (Environment)
```

### å±‚çº§ 1ï¼šç³»ç»Ÿé…ç½®

æ‰€æœ‰ç”¨æˆ·å…±äº«çš„é»˜è®¤é…ç½®ï¼š

```bash
# Linux/macOS
/etc/kimi/config.json

# Windows
C:\ProgramData\kimi\config.json
```

```json
{
  "llm_providers": {
    "openai": {
      "base_url": "https://api.openai.com/v1"
    }
  },
  "max_steps": 100,
  "timeout": 300
}
```

### å±‚çº§ 2ï¼šç”¨æˆ·é…ç½®

ä¸ªäººé…ç½®ï¼Œå­˜å‚¨åœ¨ç”¨æˆ·ä¸»ç›®å½•ï¼š

```bash
# Linux/macOS
~/.kimi/config.json

# Windows
%USERPROFILE%\.kimi\config.json
```

```json
{
  "default_model": "gpt-4",
  "llm_providers": {
    "openai": {
      "api_key_env": "OPENAI_API_KEY"
    }
  },
  "ui_mode": "shell"
}
```

### å±‚çº§ 3ï¼šé¡¹ç›®é…ç½®

é¡¹ç›®ç‰¹å®šé…ç½®ï¼Œå­˜å‚¨åœ¨é¡¹ç›®æ ¹ç›®å½•ï¼š

```bash
# é¡¹ç›®æ ¹ç›®å½•
./kimi.json
```

```json
{
  "default_model": "gpt-3.5-turbo",  // é¡¹ç›®ç”¨ä¾¿å®œçš„æ¨¡å‹
  "max_steps": 50,  // é™åˆ¶æ­¥æ•°
  "work_dir": "./workspace",  // å·¥ä½œç›®å½•
  "prompt_file": "./custom_prompt.md"  // è‡ªå®šä¹‰æç¤ºè¯
}
```

### å±‚çº§ 4ï¼šç¯å¢ƒå˜é‡

æœ€é«˜ä¼˜å…ˆçº§ï¼Œè¿è¡Œæ—¶è¦†ç›–ï¼š

```bash
# ä¸´æ—¶åˆ‡æ¢æ¨¡å‹
KIMI_MODEL=gpt-4-turbo kimi

# ä¸´æ—¶åˆ‡æ¢ API Key
OPENAI_API_KEY=sk-xxx kimi

# ä¸´æ—¶å¼€å¯è°ƒè¯•
KIMI_DEBUG=1 kimi
```

## 15.3 å®Œæ•´é…ç½®å®ç°

### é…ç½®æ•°æ®ç»“æ„

```python
# config/schema.py

from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, Optional

@dataclass
class LLMProvider:
    """LLM æä¾›å•†é…ç½®"""
    base_url: str
    api_key_env: Optional[str] = None
    timeout: int = 300
    max_retries: int = 3

@dataclass
class LLMModel:
    """LLM æ¨¡å‹é…ç½®"""
    provider: str
    name: str
    max_tokens: int
    cost_per_1k_input: float
    cost_per_1k_output: float
    temperature: float = 0.7
    supports_streaming: bool = True
    supports_vision: bool = False

@dataclass
class Config:
    """å®Œæ•´é…ç½®"""
    # LLM é…ç½®
    llm_providers: Dict[str, LLMProvider] = field(default_factory=dict)
    llm_models: Dict[str, LLMModel] = field(default_factory=dict)
    default_model: str = "gpt-4"

    # Agent é…ç½®
    max_steps: int = 100
    timeout: int = 300
    approval_required: bool = True

    # UI é…ç½®
    ui_mode: str = "shell"
    ui_format: str = "text"
    verbose: bool = False

    # è·¯å¾„é…ç½®
    work_dir: Optional[Path] = None
    prompt_file: Optional[Path] = None
    sessions_dir: Optional[Path] = None

    # æ—¥å¿—é…ç½®
    log_level: str = "INFO"
    log_file: Optional[Path] = None
```

### é…ç½®åŠ è½½å™¨

```python
# config/loader.py

import json
import os
from pathlib import Path
from typing import Dict, Any, Optional

class ConfigLoader:
    """é…ç½®åŠ è½½å™¨"""

    def __init__(self):
        self.system_config_path = self._get_system_config_path()
        self.user_config_path = self._get_user_config_path()

    def _get_system_config_path(self) -> Path:
        """è·å–ç³»ç»Ÿé…ç½®è·¯å¾„"""
        if os.name == 'nt':  # Windows
            return Path(os.getenv('PROGRAMDATA', 'C:/ProgramData')) / 'kimi' / 'config.json'
        else:  # Linux/macOS
            return Path('/etc/kimi/config.json')

    def _get_user_config_path(self) -> Path:
        """è·å–ç”¨æˆ·é…ç½®è·¯å¾„"""
        return Path.home() / '.kimi' / 'config.json'

    def _get_project_config_path(self, work_dir: Path) -> Optional[Path]:
        """è·å–é¡¹ç›®é…ç½®è·¯å¾„"""
        # åœ¨å½“å‰ç›®å½•åŠçˆ¶ç›®å½•æŸ¥æ‰¾
        current = work_dir.absolute()
        while current != current.parent:
            config_file = current / 'kimi.json'
            if config_file.exists():
                return config_file
            current = current.parent
        return None

    def load(self, work_dir: Optional[Path] = None) -> Config:
        """åŠ è½½å®Œæ•´é…ç½®ï¼ˆåˆå¹¶æ‰€æœ‰å±‚çº§ï¼‰"""
        work_dir = work_dir or Path.cwd()

        # 1. åŠ è½½ç³»ç»Ÿé…ç½®
        system_config = self._load_file(self.system_config_path)

        # 2. åŠ è½½ç”¨æˆ·é…ç½®
        user_config = self._load_file(self.user_config_path)

        # 3. åŠ è½½é¡¹ç›®é…ç½®
        project_config_path = self._get_project_config_path(work_dir)
        project_config = self._load_file(project_config_path) if project_config_path else {}

        # 4. åˆå¹¶é…ç½®ï¼ˆä¼˜å…ˆçº§ï¼šé¡¹ç›® > ç”¨æˆ· > ç³»ç»Ÿï¼‰
        merged = self._merge_configs(
            system_config,
            user_config,
            project_config
        )

        # 5. åº”ç”¨ç¯å¢ƒå˜é‡
        merged = self._apply_env_vars(merged)

        # 6. éªŒè¯é…ç½®
        self._validate(merged)

        # 7. è½¬æ¢ä¸º Config å¯¹è±¡
        return self._to_config_object(merged)

    def _load_file(self, path: Optional[Path]) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if not path or not path.exists():
            return {}

        try:
            with open(path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except json.JSONDecodeError as e:
            raise ValueError(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {path}\n{e}")

    def _merge_configs(self, *configs: Dict[str, Any]) -> Dict[str, Any]:
        """æ·±åº¦åˆå¹¶å¤šä¸ªé…ç½®"""
        result = {}
        for config in configs:
            self._deep_merge(result, config)
        return result

    def _deep_merge(self, base: Dict, overlay: Dict):
        """æ·±åº¦åˆå¹¶ä¸¤ä¸ªå­—å…¸"""
        for key, value in overlay.items():
            if key in base and isinstance(base[key], dict) and isinstance(value, dict):
                self._deep_merge(base[key], value)
            else:
                base[key] = value

    def _apply_env_vars(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """åº”ç”¨ç¯å¢ƒå˜é‡è¦†ç›–"""
        # KIMI_MODEL -> default_model
        if os.getenv('KIMI_MODEL'):
            config['default_model'] = os.getenv('KIMI_MODEL')

        # KIMI_DEBUG -> log_level
        if os.getenv('KIMI_DEBUG'):
            config['log_level'] = 'DEBUG'

        # KIMI_MODE -> ui_mode
        if os.getenv('KIMI_MODE'):
            config['ui_mode'] = os.getenv('KIMI_MODE')

        # KIMI_MAX_STEPS -> max_steps
        if os.getenv('KIMI_MAX_STEPS'):
            config['max_steps'] = int(os.getenv('KIMI_MAX_STEPS'))

        return config

    def _validate(self, config: Dict[str, Any]):
        """éªŒè¯é…ç½®"""
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        if 'llm_providers' not in config or not config['llm_providers']:
            raise ValueError("é…ç½®ä¸­å¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ª LLM æä¾›å•†")

        # æ£€æŸ¥é»˜è®¤æ¨¡å‹å­˜åœ¨
        default_model = config.get('default_model')
        if default_model and default_model not in config.get('llm_models', {}):
            raise ValueError(f"é»˜è®¤æ¨¡å‹ '{default_model}' ä¸å­˜åœ¨äºé…ç½®ä¸­")

        # æ£€æŸ¥æ•°å€¼èŒƒå›´
        if config.get('max_steps', 0) <= 0:
            raise ValueError("max_steps å¿…é¡»å¤§äº 0")

    def _to_config_object(self, data: Dict[str, Any]) -> Config:
        """è½¬æ¢ä¸º Config å¯¹è±¡"""
        # è½¬æ¢ providers
        providers = {
            name: LLMProvider(**provider_data)
            for name, provider_data in data.get('llm_providers', {}).items()
        }

        # è½¬æ¢ models
        models = {
            name: LLMModel(**model_data)
            for name, model_data in data.get('llm_models', {}).items()
        }

        # è½¬æ¢è·¯å¾„
        work_dir = Path(data['work_dir']) if data.get('work_dir') else None
        prompt_file = Path(data['prompt_file']) if data.get('prompt_file') else None
        sessions_dir = Path(data['sessions_dir']) if data.get('sessions_dir') else None
        log_file = Path(data['log_file']) if data.get('log_file') else None

        return Config(
            llm_providers=providers,
            llm_models=models,
            default_model=data.get('default_model', 'gpt-4'),
            max_steps=data.get('max_steps', 100),
            timeout=data.get('timeout', 300),
            approval_required=data.get('approval_required', True),
            ui_mode=data.get('ui_mode', 'shell'),
            ui_format=data.get('ui_format', 'text'),
            verbose=data.get('verbose', False),
            work_dir=work_dir,
            prompt_file=prompt_file,
            sessions_dir=sessions_dir,
            log_level=data.get('log_level', 'INFO'),
            log_file=log_file
        )
```

## 15.4 ç§˜å¯†ç®¡ç†

### æ–¹æ¡ˆ 1ï¼šç¯å¢ƒå˜é‡

```bash
# .env æ–‡ä»¶ï¼ˆä¸æäº¤åˆ° Gitï¼‰
OPENAI_API_KEY=sk-xxx
MOONSHOT_API_KEY=sk-yyy
DATABASE_PASSWORD=zzz
```

```python
# åŠ è½½ .env
from dotenv import load_dotenv
load_dotenv()

# ä»ç¯å¢ƒå˜é‡è¯»å–
api_key = os.getenv('OPENAI_API_KEY')
```

### æ–¹æ¡ˆ 2ï¼šå¯†é’¥ç®¡ç†æœåŠ¡

```python
# config/secrets.py

class SecretManager:
    """å¯†é’¥ç®¡ç†å™¨"""

    def __init__(self, backend: str = "env"):
        self.backend = backend

    def get_secret(self, key: str) -> str:
        """è·å–å¯†é’¥"""
        if self.backend == "env":
            return self._get_from_env(key)
        elif self.backend == "keyring":
            return self._get_from_keyring(key)
        elif self.backend == "vault":
            return self._get_from_vault(key)

    def _get_from_env(self, key: str) -> str:
        """ä»ç¯å¢ƒå˜é‡è·å–"""
        value = os.getenv(key)
        if not value:
            raise ValueError(f"ç¯å¢ƒå˜é‡ {key} æœªè®¾ç½®")
        return value

    def _get_from_keyring(self, key: str) -> str:
        """ä»ç³»ç»Ÿå¯†é’¥é“¾è·å–"""
        import keyring
        value = keyring.get_password("kimi", key)
        if not value:
            raise ValueError(f"å¯†é’¥ {key} ä¸å­˜åœ¨")
        return value

    def _get_from_vault(self, key: str) -> str:
        """ä» Vault è·å–"""
        import hvac
        client = hvac.Client(url=os.getenv('VAULT_URL'))
        client.token = os.getenv('VAULT_TOKEN')
        secret = client.secrets.kv.v2.read_secret_version(path=key)
        return secret['data']['data']['value']
```

### æ–¹æ¡ˆ 3ï¼šåŠ å¯†é…ç½®

```python
# åŠ å¯†æ•æ„Ÿé…ç½®
from cryptography.fernet import Fernet

class EncryptedConfig:
    """åŠ å¯†é…ç½®"""

    def __init__(self, key_file: Path):
        # ä»æ–‡ä»¶è¯»å–åŠ å¯†å¯†é’¥
        with open(key_file, 'rb') as f:
            self.key = f.read()
        self.fernet = Fernet(self.key)

    def encrypt_value(self, value: str) -> str:
        """åŠ å¯†å€¼"""
        return self.fernet.encrypt(value.encode()).decode()

    def decrypt_value(self, encrypted: str) -> str:
        """è§£å¯†å€¼"""
        return self.fernet.decrypt(encrypted.encode()).decode()

    def save_encrypted(self, config: dict, path: Path):
        """ä¿å­˜åŠ å¯†é…ç½®"""
        encrypted = {}
        for key, value in config.items():
            if key.endswith('_key') or key.endswith('_password'):
                encrypted[key] = self.encrypt_value(value)
            else:
                encrypted[key] = value

        with open(path, 'w') as f:
            json.dump(encrypted, f)
```

## 15.5 å¤šç¯å¢ƒæ”¯æŒ

### ç¯å¢ƒé…ç½®æ–‡ä»¶

```bash
.kimi/
â”œâ”€â”€ config.json          # åŸºç¡€é…ç½®
â”œâ”€â”€ config.dev.json      # å¼€å‘ç¯å¢ƒ
â”œâ”€â”€ config.staging.json  # é¢„å‘ç¯å¢ƒ
â””â”€â”€ config.prod.json     # ç”Ÿäº§ç¯å¢ƒ
```

```python
# config/environment.py

class EnvironmentConfig:
    """ç¯å¢ƒé…ç½®ç®¡ç†"""

    def __init__(self, base_dir: Path):
        self.base_dir = base_dir

    def load_for_env(self, env: str = None) -> Config:
        """åŠ è½½æŒ‡å®šç¯å¢ƒçš„é…ç½®"""
        # 1. ç¡®å®šç¯å¢ƒ
        env = env or os.getenv('KIMI_ENV', 'dev')

        # 2. åŠ è½½åŸºç¡€é…ç½®
        base_config = self._load_file(self.base_dir / 'config.json')

        # 3. åŠ è½½ç¯å¢ƒé…ç½®
        env_config = self._load_file(self.base_dir / f'config.{env}.json')

        # 4. åˆå¹¶
        merged = {**base_config, **env_config}

        return Config(**merged)
```

### ç¯å¢ƒé…ç½®ç¤ºä¾‹

```json
// config.dev.json
{
  "default_model": "gpt-3.5-turbo",  // å¼€å‘ç”¨ä¾¿å®œæ¨¡å‹
  "log_level": "DEBUG",
  "approval_required": false,  // å¼€å‘ä¸éœ€è¦å®¡æ‰¹
  "llm_providers": {
    "openai": {
      "base_url": "http://localhost:8000/v1"  // æœ¬åœ°ä»£ç†
    }
  }
}

// config.prod.json
{
  "default_model": "gpt-4-turbo",  // ç”Ÿäº§ç”¨æœ€å¼ºæ¨¡å‹
  "log_level": "INFO",
  "approval_required": true,  // ç”Ÿäº§éœ€è¦å®¡æ‰¹
  "max_steps": 50,  // é™åˆ¶æ­¥æ•°
  "timeout": 600
}
```

## 15.6 é…ç½®çƒ­æ›´æ–°

```python
# config/watcher.py

import time
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

class ConfigWatcher(FileSystemEventHandler):
    """é…ç½®æ–‡ä»¶ç›‘å¬å™¨"""

    def __init__(self, config_file: Path, on_reload):
        self.config_file = config_file
        self.on_reload = on_reload
        self.last_modified = 0

    def on_modified(self, event):
        """æ–‡ä»¶ä¿®æ”¹å›è°ƒ"""
        if event.src_path != str(self.config_file):
            return

        # é˜²æ­¢é‡å¤è§¦å‘
        current_time = time.time()
        if current_time - self.last_modified < 1:
            return
        self.last_modified = current_time

        # é‡æ–°åŠ è½½é…ç½®
        try:
            new_config = ConfigLoader().load()
            self.on_reload(new_config)
            print("âœ… é…ç½®å·²é‡æ–°åŠ è½½")
        except Exception as e:
            print(f"âŒ é…ç½®é‡æ–°åŠ è½½å¤±è´¥: {e}")

def watch_config(config_file: Path, on_reload):
    """ç›‘å¬é…ç½®æ–‡ä»¶å˜åŒ–"""
    observer = Observer()
    handler = ConfigWatcher(config_file, on_reload)
    observer.schedule(handler, str(config_file.parent), recursive=False)
    observer.start()
    return observer

# ä½¿ç”¨ç¤ºä¾‹
def reload_agent_config(new_config: Config):
    """é‡æ–°åŠ è½½ Agent é…ç½®"""
    agent.update_config(new_config)

observer = watch_config(
    Path.home() / '.kimi' / 'config.json',
    reload_agent_config
)
```

## 15.7 é…ç½®è¿ç§»

### ç‰ˆæœ¬æ£€æµ‹

```python
# config/migration.py

class ConfigMigrator:
    """é…ç½®è¿ç§»å™¨"""

    def migrate(self, config_data: dict) -> dict:
        """è¿ç§»é…ç½®åˆ°æœ€æ–°ç‰ˆæœ¬"""
        version = config_data.get('version', 1)

        # åº”ç”¨æ‰€æœ‰å¿…è¦çš„è¿ç§»
        if version < 2:
            config_data = self._migrate_v1_to_v2(config_data)
        if version < 3:
            config_data = self._migrate_v2_to_v3(config_data)

        config_data['version'] = 3
        return config_data

    def _migrate_v1_to_v2(self, config: dict) -> dict:
        """v1 -> v2: æ·»åŠ  provider æ”¯æŒ"""
        # å°†æ—§çš„ api_key ç§»åˆ° provider é…ç½®
        if 'api_key' in config:
            config['llm_providers'] = {
                'openai': {
                    'api_key_env': 'OPENAI_API_KEY'
                }
            }
            del config['api_key']
        return config

    def _migrate_v2_to_v3(self, config: dict) -> dict:
        """v2 -> v3: æ·»åŠ æˆæœ¬è¿½è¸ª"""
        # ä¸ºæ‰€æœ‰æ¨¡å‹æ·»åŠ æˆæœ¬ä¿¡æ¯
        for model_name, model_config in config.get('llm_models', {}).items():
            if 'cost_per_1k_input' not in model_config:
                model_config['cost_per_1k_input'] = 0.01
                model_config['cost_per_1k_output'] = 0.03
        return config
```

## 15.8 å¸¸è§é™·é˜±

### é™·é˜± 1ï¼šç¡¬ç¼–ç é…ç½®

```python
# âŒ é”™è¯¯ï¼šç¡¬ç¼–ç 
api_key = "sk-xxx"  # æ³„éœ²é£é™©ï¼
base_url = "https://api.openai.com/v1"  # ä¸çµæ´»

# âœ… æ­£ç¡®ï¼šä»é…ç½®è¯»å–
config = ConfigLoader().load()
provider = config.get_provider('openai')
api_key = provider.api_key
```

### é™·é˜± 2ï¼šå¿½ç•¥ä¼˜å…ˆçº§

```python
# âŒ é”™è¯¯ï¼šåªè¯»å–ä¸€ä¸ªé…ç½®æ–‡ä»¶
config = json.load(open('config.json'))

# âœ… æ­£ç¡®ï¼šåˆå¹¶æ‰€æœ‰å±‚çº§
config = ConfigLoader().load()  # è‡ªåŠ¨åˆå¹¶æ‰€æœ‰å±‚çº§
```

### é™·é˜± 3ï¼šæ˜æ–‡å­˜å‚¨å¯†é’¥

```python
# âŒ é”™è¯¯ï¼šé…ç½®æ–‡ä»¶ä¸­æ˜æ–‡å­˜å‚¨
{
  "api_key": "sk-xxx"  // æäº¤åˆ° Gitï¼
}

# âœ… æ­£ç¡®ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡å¼•ç”¨
{
  "api_key_env": "OPENAI_API_KEY"  // å¼•ç”¨ç¯å¢ƒå˜é‡
}
```

## 15.9 æœ€ä½³å®è·µ

### 1. é…ç½®æ¨¡æ¿

æä¾›é…ç½®æ¨¡æ¿ä¾›ç”¨æˆ·å¤åˆ¶ï¼š

```bash
.kimi/
â”œâ”€â”€ config.template.json  # æ¨¡æ¿
â””â”€â”€ .gitignore            # å¿½ç•¥ config.json
```

```json
// config.template.json
{
  "llm_providers": {
    "openai": {
      "base_url": "https://api.openai.com/v1",
      "api_key_env": "OPENAI_API_KEY"
    }
  },
  "default_model": "gpt-4",
  "max_steps": 100
}
```

### 2. é…ç½®éªŒè¯

å¯åŠ¨æ—¶éªŒè¯é…ç½®ï¼š

```python
def validate_config(config: Config):
    """éªŒè¯é…ç½®"""
    errors = []

    # æ£€æŸ¥ API Key
    for provider_name, provider in config.llm_providers.items():
        if provider.api_key_env:
            if not os.getenv(provider.api_key_env):
                errors.append(f"ç¯å¢ƒå˜é‡ {provider.api_key_env} æœªè®¾ç½®")

    # æ£€æŸ¥è·¯å¾„
    if config.work_dir and not config.work_dir.exists():
        errors.append(f"å·¥ä½œç›®å½•ä¸å­˜åœ¨: {config.work_dir}")

    if errors:
        raise ValueError("é…ç½®éªŒè¯å¤±è´¥:\n" + "\n".join(f"- {e}" for e in errors))
```

### 3. é…ç½®æ–‡æ¡£

ç”Ÿæˆé…ç½®æ–‡æ¡£ï¼š

```python
def generate_config_docs(config: Config) -> str:
    """ç”Ÿæˆé…ç½®æ–‡æ¡£"""
    docs = []
    docs.append("# å½“å‰é…ç½®\n")
    docs.append(f"é»˜è®¤æ¨¡å‹: {config.default_model}")
    docs.append(f"æœ€å¤§æ­¥æ•°: {config.max_steps}")
    docs.append(f"UI æ¨¡å¼: {config.ui_mode}")

    docs.append("\n## LLM æä¾›å•†\n")
    for name, provider in config.llm_providers.items():
        docs.append(f"- {name}: {provider.base_url}")

    return "\n".join(docs)
```

## 15.10 FAQ

**Q: å¦‚ä½•åˆ‡æ¢ä¸åŒçš„ API Keyï¼Ÿ**

A: ä½¿ç”¨ç¯å¢ƒå˜é‡è¦†ç›–ï¼š
```bash
OPENAI_API_KEY=sk-personal kimi  # ä½¿ç”¨ä¸ªäºº Key
OPENAI_API_KEY=sk-company kimi   # ä½¿ç”¨å…¬å¸ Key
```

**Q: é…ç½®æ–‡ä»¶æ”¾åœ¨å“ªé‡Œæœ€å¥½ï¼Ÿ**

A: æ¨èé¡ºåºï¼š
1. é¡¹ç›®ç‰¹å®šé…ç½® â†’ `./kimi.json`
2. ç”¨æˆ·é…ç½® â†’ `~/.kimi/config.json`
3. ç³»ç»Ÿé…ç½® â†’ `/etc/kimi/config.json`

**Q: å¦‚ä½•åœ¨ CI/CD ä¸­ä½¿ç”¨é…ç½®ï¼Ÿ**

A: ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼š
```yaml
# .github/workflows/test.yml
env:
  KIMI_MODEL: gpt-3.5-turbo
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  KIMI_MAX_STEPS: 20
```

## 15.11 ç»ƒä¹ 

### ç»ƒä¹  1: å®ç°é…ç½®å‘½ä»¤

æ·»åŠ  CLI å‘½ä»¤æŸ¥çœ‹å’Œä¿®æ”¹é…ç½®ï¼š

```python
@click.group()
def config():
    """é…ç½®ç®¡ç†"""
    pass

@config.command()
def show():
    """æ˜¾ç¤ºå½“å‰é…ç½®"""
    # TODO: å®ç°æ˜¾ç¤ºé…ç½®
    pass

@config.command()
@click.argument('key')
@click.argument('value')
def set(key, value):
    """è®¾ç½®é…ç½®é¡¹"""
    # TODO: å®ç°è®¾ç½®é…ç½®
    pass
```

### ç»ƒä¹  2: å®ç°é…ç½®æ ¡éªŒ

æ·»åŠ é…ç½® schema æ ¡éªŒï¼š

```python
from jsonschema import validate

CONFIG_SCHEMA = {
    "type": "object",
    "properties": {
        "default_model": {"type": "string"},
        "max_steps": {"type": "number", "minimum": 1}
    },
    "required": ["default_model"]
}

def validate_config(config_data: dict):
    """æ ¡éªŒé…ç½®æ ¼å¼"""
    # TODO: ä½¿ç”¨ jsonschema æ ¡éªŒ
    pass
```

### ç»ƒä¹  3: å®ç°é…ç½®å¯¼å…¥å¯¼å‡º

æ”¯æŒå¯¼å…¥å¯¼å‡ºé…ç½®ï¼š

```python
class ConfigManager:
    def export_config(self, output_path: Path):
        """å¯¼å‡ºé…ç½®åˆ°æ–‡ä»¶"""
        # TODO: å¯¼å‡ºé…ç½®ï¼ˆæ’é™¤æ•æ„Ÿä¿¡æ¯ï¼‰
        pass

    def import_config(self, input_path: Path):
        """ä»æ–‡ä»¶å¯¼å…¥é…ç½®"""
        # TODO: å¯¼å…¥å¹¶éªŒè¯é…ç½®
        pass
```

## 15.12 å°ç»“

æœ¬ç« å­¦ä¹ äº†ï¼š

- âœ… **é…ç½®å±‚çº§**ï¼šç³»ç»Ÿã€ç”¨æˆ·ã€é¡¹ç›®ã€ç¯å¢ƒå˜é‡
- âœ… **ç§˜å¯†ç®¡ç†**ï¼šç¯å¢ƒå˜é‡ã€å¯†é’¥æœåŠ¡ã€åŠ å¯†å­˜å‚¨
- âœ… **å¤šç¯å¢ƒæ”¯æŒ**ï¼šdevã€stagingã€prod
- âœ… **é…ç½®çƒ­æ›´æ–°**ï¼šç›‘å¬æ–‡ä»¶å˜åŒ–
- âœ… **é…ç½®è¿ç§»**ï¼šç‰ˆæœ¬ç®¡ç†å’Œå‡çº§

**å…³é”®è¦ç‚¹**:

1. ä½¿ç”¨åˆ†å±‚é…ç½®ï¼Œæä¾›çµæ´»æ€§
2. æ°¸è¿œä¸è¦ç¡¬ç¼–ç æ•æ„Ÿä¿¡æ¯
3. æ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–
4. æä¾›é…ç½®éªŒè¯å’Œé»˜è®¤å€¼
5. æ–‡æ¡£åŒ–æ‰€æœ‰é…ç½®é€‰é¡¹

é…ç½®ç³»ç»Ÿæä¾›ï¼š

- ğŸ”§ **çµæ´»æ€§**ï¼šé€‚åº”ä¸åŒç¯å¢ƒ
- ğŸ”’ **å®‰å…¨æ€§**ï¼šä¿æŠ¤æ•æ„Ÿä¿¡æ¯
- ğŸ¯ **ä¾¿æ·æ€§**ï¼šå¤šå±‚çº§è¦†ç›–
- ğŸ“ **å¯ç»´æŠ¤æ€§**ï¼šæ¸…æ™°çš„é…ç½®ç»“æ„

---

**ä¸Šä¸€ç« **ï¼š[ç¬¬ 14 ç« ï¼šUI æ¨¡å¼](./14-ui-modes.md) â†
**ä¸‹ä¸€ç« **ï¼š[ç¬¬ 16 ç« ï¼šä¼šè¯ç®¡ç†](./16-session-management.md) â†’
